# üöÄ Project: Tweet Sentiment Analyzer Ml Intern

![Status](https://img.shields.io/badge/Status-Active_Simulation-success)
![Role](https://img.shields.io/badge/Role-Junior_Developer-blue)

## üìã Mission Briefing
Welcome to the team. Your task is to implement the features listed below.
The environment has been pre-configured with the necessary starter files.

## üìÇ Repository Contents
| File | Description |
|------|-------------|
| `requirements.txt` | Pre-loaded starter code |
| `app.py` | Pre-loaded starter code |
| `data/tweets.csv` | Pre-loaded starter code |


---

## üéüÔ∏è Your Assignment Checklist
Please complete the tickets in order.

### ‚¨ú Ticket #1: üß± Mission 1: Data Ingestion & Preprocessing
**Objective:** Load a dataset of tweets and preprocess the text for machine learning.

**Context:** High-quality data is the foundation of any robust ML model. Cleaning and transforming raw text into a numerical format is crucial for model training, removing noise, and improving model performance.

**Orders:**
- [ ] Load the provided `data/tweets.csv` into a Pandas DataFrame. The CSV should contain 'text' (the tweet content) and 'sentiment' (the label) columns.
- [ ] Implement a text cleaning function that performs the following: converts text to lowercase, removes URLs, mentions (e.g., '@username'), hashtags (e.g., '#topic'), and punctuation.
- [ ] Apply the cleaning function to the 'text' column of your DataFrame.
- [ ] Tokenize the cleaned text using a suitable library (e.g., NLTK's `word_tokenize`).
- [ ] Convert the tokenized text into numerical features using TF-IDF vectorization (from `sklearn.feature_extraction.text.TfidfVectorizer`).

<br>

### ‚¨ú Ticket #2: üß† Mission 2: Sentiment Model Training & Evaluation
**Objective:** Train a machine learning model to classify tweet sentiment and evaluate its performance.

**Context:** Building a predictive model involves selecting an appropriate algorithm, training it on preprocessed data, and rigorously assessing its accuracy to ensure it meets performance benchmarks and generalizes well to unseen data.

**Orders:**
- [ ] Split your preprocessed data (TF-IDF features) and sentiment labels into training and testing sets (e.g., an 80/20 split) using `sklearn.model_selection.train_test_split`.
- [ ] Choose a classification algorithm suitable for text classification (e.g., `LogisticRegression`, `SVC`, or `MultinomialNB` from scikit-learn). Instantiate and configure it.
- [ ] Train the chosen model on your training data (TF-IDF features and sentiment labels).
- [ ] Make predictions on the test set.
- [ ] Calculate and print standard evaluation metrics: accuracy, precision, recall, and F1-score (using `sklearn.metrics`).
- [ ] Save the trained model and the TF-IDF vectorizer using `joblib.dump` (or `pickle`) for later use in the API.

<br>

### ‚¨ú Ticket #3: üåê Mission 3: REST API for Real-time Predictions
**Objective:** Develop a simple Flask (or FastAPI) API endpoint that accepts raw tweet text and returns its predicted sentiment.

**Context:** To make the trained model useful in real-world applications, it needs to be exposed through an API. This allows other services or user interfaces to seamlessly integrate and consume its predictions without needing to understand the underlying ML model.

**Orders:**
- [ ] Create a Flask application in `app.py`.
- [ ] At application startup, load the saved TF-IDF vectorizer and the trained sentiment model from Mission 2.
- [ ] Define a POST endpoint, for example, `/predict_sentiment`, that accepts JSON input with a 'tweet_text' field.
- [ ] Inside the endpoint, apply the same text preprocessing and tokenization steps (from Mission 1) to the incoming 'tweet_text'.
- [ ] Vectorize the preprocessed text using the loaded TF-IDF vectorizer.
- [ ] Use the loaded model to predict the sentiment of the vectorized text.
- [ ] Return the predicted sentiment as a JSON response (e.g., `{'sentiment': 'positive'}`).

<br>

---

## üöÄ Submission Guide
1. **Clone** this repo.
2. **Code** the solution for each ticket.
3. **Push** to `main`.
4. **Submit** for review on your dashboard.

*Generated by Shadow Workplace AI*
